{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Testing\n",
    "\n",
    "How to write correct code and go back to enjoy your life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Correct code is a code without bugs or errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### bug\n",
    "\n",
    "> there is a bug in the code when this code behave differently from what it's written in its documentation\n",
    "\n",
    "In the documentation we include the external documentation (**the manual**) the internal one (**docstrings**) and the implicit one (**name** of the function and of its **arguments**)\n",
    "\n",
    "Can be considered bugs also **comments** and **variable names** that do not align with what the code is doing, even if less so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### the most bugged function in history\n",
    "\n",
    "> **REQUIREMENT**: write a function that integrate a parabola between two positions\n",
    "\n",
    "```python\n",
    "def multiplication(first_name, last_name):\n",
    "    \"\"\"this function divides two numbers\"\"\"\n",
    "    # perform the subtraction\n",
    "    exponent = first_name[last_name]\n",
    "    return exponent\n",
    "```\n",
    "\n",
    "the code runs fine without any errors (if I give the proper parameters), but using it in real life would be suicidal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### error\n",
    "\n",
    "> a code has an error when behaves differently from what it was written to do (logic and behavior differ)\n",
    "\n",
    "For example, a sorting algorithm that does not sort, or that in some corner cases sort incorrectly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## good documentation\n",
    "\n",
    "Take the documentation of numpy, it's basically as good as it gets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Compute the eigenvalues and right eigenvectors of a square array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : (..., M, M) array\n",
      "        Matrices for which the eigenvalues and right eigenvectors will\n",
      "        be computed\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    w : (..., M) array\n",
      "        The eigenvalues, each repeated according to its multiplicity.\n",
      "        The eigenvalues are not necessarily ordered. The resulting\n",
      "        array will be of complex type, unless the imaginary part is\n",
      "        zero in which case it will be cast to a real type. When `a`\n",
      "        is real the resulting eigenvalues will be real (0 imaginary\n",
      "        part) or occur in conjugate pairs\n",
      "\n",
      "    v : (..., M, M) array\n",
      "        The normalized (unit \"length\") eigenvectors, such that the\n",
      "        column ``v[:,i]`` is the eigenvector corresponding to the\n",
      "        eigenvalue ``w[i]``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(\"\\n\".join(numpy.linalg.eig.__doc__.splitlines()[:24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raises\n",
      "    ------\n",
      "    LinAlgError\n",
      "        If the eigenvalue computation does not converge.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    eigvals : eigenvalues of a non-symmetric array.\n",
      "\n",
      "    eigh : eigenvalues and eigenvectors of a real symmetric or complex \n",
      "           Hermitian (conjugate symmetric) array.\n",
      "\n",
      "    eigvalsh : eigenvalues of a real symmetric or complex Hermitian\n",
      "               (conjugate symmetric) array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(numpy.linalg.eig.__doc__.splitlines()[24:39]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Notes\n",
      "    -----\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "    Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "    details.\n",
      "\n",
      "    This is implemented using the _geev LAPACK routines which compute\n",
      "    the eigenvalues and eigenvectors of general square arrays.\n",
      "\n",
      "    The number `w` is an eigenvalue of `a` if there exists a vector\n",
      "    `v` such that ``dot(a,v) = w * v``. Thus, the arrays `a`, `w`, and\n",
      "    `v` satisfy the equations ``dot(a[:,:], v[:,i]) = w[i] * v[:,i]``\n",
      "    for :math:`i \\in \\{0,...,M-1\\}`.\n",
      "\n",
      "    The array `v` of eigenvectors may not be of maximum rank, that is, some\n",
      "    of the columns may be linearly dependent, although round-off error may\n",
      "    obscure that fact. If the eigenvalues are all different, then theoretically\n",
      "    the eigenvectors are linearly independent. Likewise, the (complex-valued)\n",
      "    matrix of eigenvectors `v` is unitary if the matrix `a` is normal, i.e.,\n",
      "    if ``dot(a, a.H) = dot(a.H, a)``, where `a.H` denotes the conjugate\n",
      "    transpose of `a`.\n",
      "\n",
      "    Finally, it is emphasized that `v` consists of the *right* (as in\n",
      "    right-hand side) eigenvectors of `a`.  A vector `y` satisfying\n",
      "    ``dot(y.T, a) = z * y.T`` for some number `z` is called a *left*\n",
      "    eigenvector of `a`, and, in general, the left and right eigenvectors\n",
      "    of a matrix are not necessarily the (perhaps conjugate) transposes\n",
      "    of each other.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(numpy.linalg.eig.__doc__.splitlines()[39:70]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    References\n",
      "    ----------\n",
      "    G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL,\n",
      "    Academic Press, Inc., 1980, Various pp.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from numpy import linalg as LA\n",
      "\n",
      "    (Almost) trivial example with real e-values and e-vectors.\n",
      "\n",
      "    >>> w, v = LA.eig(np.diag((1, 2, 3)))\n",
      "    >>> w; v\n",
      "    array([ 1.,  2.,  3.])\n",
      "    array([[ 1.,  0.,  0.],\n",
      "           [ 0.,  1.,  0.],\n",
      "           [ 0.,  0.,  1.]])\n",
      "\n",
      "    Real matrix possessing complex e-values and e-vectors; note that the\n",
      "    e-values are complex conjugates of each other.\n",
      "\n",
      "    >>> w, v = LA.eig(np.array([[1, -1], [1, 1]]))\n",
      "    >>> w; v\n",
      "    array([ 1. + 1.j,  1. - 1.j])\n",
      "    array([[ 0.70710678+0.j        ,  0.70710678+0.j        ],\n",
      "           [ 0.00000000-0.70710678j,  0.00000000+0.70710678j]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(numpy.linalg.eig.__doc__.splitlines()[70:96]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Complex-valued matrix with real e-values (but complex-valued e-vectors);\n",
      "    note that a.conj().T = a, i.e., a is Hermitian.\n",
      "\n",
      "    >>> a = np.array([[1, 1j], [-1j, 1]])\n",
      "    >>> w, v = LA.eig(a)\n",
      "    >>> w; v\n",
      "    array([  2.00000000e+00+0.j,   5.98651912e-36+0.j]) # i.e., {2, 0}\n",
      "    array([[ 0.00000000+0.70710678j,  0.70710678+0.j        ],\n",
      "           [ 0.70710678+0.j        ,  0.00000000+0.70710678j]])\n",
      "\n",
      "    Be careful about round-off error!\n",
      "\n",
      "    >>> a = np.array([[1 + 1e-9, 0], [0, 1 - 1e-9]])\n",
      "    >>> # Theor. e-values are 1 +/- 1e-9\n",
      "    >>> w, v = LA.eig(a)\n",
      "    >>> w; v\n",
      "    array([ 1.,  1.])\n",
      "    array([[ 1.,  0.],\n",
      "           [ 0.,  1.]])\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(numpy.linalg.eig.__doc__.splitlines()[96:120]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Purity of functions\n",
    "\n",
    "A function is called pure if\n",
    "\n",
    "1. with the same input, it returns the same output (it is deterministic)\n",
    "2. it does not change the state of the rest of the program.\n",
    "\n",
    "This lets you:\n",
    "\n",
    "1. know that once you've proven that function is correct, it will always be correct\n",
    "2. if you change the implementation, as long as the input-output relationship is the same, the functions that depend on it are going to be fine\n",
    "\n",
    "pure functions are very useful, in particular because they are the easier to test and prove correct\n",
    "\n",
    "Using global variables (or non local ones) inside a function stops it from being pure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## types of test\n",
    "\n",
    "we want to test if a function is correct, what kind of test can be done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **advancement test**: edits to the function introduce the new features I deside\n",
    "* **regressions test**: edits to the function do not lose functionality that other code relies on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **positive tests**: the code does the things I expect it to do when I give the right parameters\n",
    "* **negative tests**: the code fail the way I expect it to when I give the wrong parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strategies of testing\n",
    "\n",
    "to test the correctness of a single function\n",
    "\n",
    "* informal testing\n",
    "* unit testing (anecdotal testing)\n",
    "* property testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Informal tests\n",
    "\n",
    "when we write a function, we usually test if it is working as we expect\n",
    "\n",
    "this is a form of testing, and is necessary, but if far from enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a12389ee159e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "assert inc(3)==4\n",
    "assert inc(5)==4\n",
    "assert inc(6)==4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unit testing (anecdotal tests)\n",
    "\n",
    "What you tested with just bare asserts, you save as a separate script\n",
    "\n",
    "any time you modify the code, run the tests to check that everything is still working according to plan.\n",
    "\n",
    "**Do not commit code that do not pass all the tests!**\n",
    "\n",
    "If you find a new bug:\n",
    "\n",
    "1. write a test that reproduce that bug (i.e. that fails for that case)\n",
    "2. adjust the function until the test passes\n",
    "3. keep the test there forever to avoid regressions in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a general rule, I need at least one example of a typical case use, plus one for any limit case.\n",
    "\n",
    "Imagine to be writing a function that sort a list.\n",
    "You would need to test at least:\n",
    "\n",
    "1. that an out of order list, such as `[1, 3, 2]`, get sorted `[1, 2, 3]`\n",
    "2. an empty list gives back an empty list\n",
    "3. an already sorted list `[1, 2, 3]` gives back the same list as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A good library to start with **unit testing** is [**pytest**](http://doc.pytest.org/).\n",
    "\n",
    "**pytest** is a command line program that:\n",
    "\n",
    "1. search all the current directory for `*.py` files\n",
    "2. in each one of those, search all the functions named `test_<something>`\n",
    "3. execute all of them and keep track of the results\n",
    "4. prints a summary of the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/enrico\n"
     ]
    }
   ],
   "source": [
    "%cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def test_answer_1():\n",
    "    assert inc(3) == 5\n",
    "    \n",
    "def test_answer_2():\n",
    "    assert inc(7) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.0, pytest-3.0.6, py-1.4.32, pluggy-0.4.0\n",
      "rootdir: /home/enrico, inifile: \n",
      "plugins: xonsh-0.5.6, hypothesis-3.6.1\n",
      "collected 2 items \u001b[0m\u001b[1m\n",
      "\u001b[0m\n",
      "test_prova.py FF\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_answer_1 _________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_answer_1():\u001b[0m\n",
      "\u001b[1m>       assert inc(3) == 5\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 4 == 5\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 4 = inc(3)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m________________________________ test_answer_2 _________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_answer_2():\u001b[0m\n",
      "\u001b[1m>       assert inc(7) == 7\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 8 == 7\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 8 = inc(7)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:8: AssertionError\n",
      "\u001b[31m\u001b[1m=========================== 2 failed in 0.03 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One could execute the test code by hand, but there would be several disadvantages\n",
    "\n",
    "1. one would have to execute each function one by one (instead of having them discovered byt pytest)\n",
    "2. at the first error, the whole execution would stop, giving me a partial view of the situations; pytest visualizes all the errors\n",
    "3. the bare *assert* results are not very informative; pytest results are more explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pytest can also check if we expect the function to raises an exception under certain circumstances.\n",
    "\n",
    "This would be quite difficult to do with normal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def test_zero_division():\n",
    "    with pytest.raises(ZeroDivisionError):\n",
    "        1 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test driven development\n",
    "\n",
    "In the **test driven development** code and tests are written together, starting from the specifics.\n",
    "\n",
    "There are several variants of this concept, but the main idea is that you shouldn't wait to finish your code to write your tests.\n",
    "\n",
    "Write them alongside, even before the code itself, so that you can be sure that the function follows what you expect it to do.\n",
    "\n",
    "When designing complicated architectures, where the design is necessarely top-down, this is a precious approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the top-down approach, we will develop our code as if everything works perfectly, and then we will implement it for real\n",
    "\n",
    "1. we start from the \"final\" function, calling the others as if they exist\n",
    "2. implement a \"stub\" function of each one, that does nothing aside of allowing us to execute our code\n",
    "3. write tests that represents the properties that we expect from our real function\n",
    "4. replace the stubs with functions that actually have these properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Cellular Automata\n",
    "\n",
    "Let's try to implement a simple cellular automata, based on the rules detailed by Wolfram\n",
    "\n",
    "Our system is represented by a string of 0 and empty spaces (alive and dead cells), and the evolution is based on the status of each characted and its neighbours\n",
    "\n",
    "\n",
    "We will use [rule 30](http://mathworld.wolfram.com/Rule30.html), inspired by [this blog](http://faingezicht.com/articles/2017/01/23/wolfram/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rule30 = {\"000\": '.',\n",
    "          \"00.\": '.',\n",
    "          \"0.0\": '.',\n",
    "          \"...\": '.',\n",
    "          \"0..\": '0',\n",
    "          \".00\": '0',\n",
    "          \".0.\": '0',\n",
    "          \"..0\": '0',\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def simulation(nsteps):\n",
    "    initial_state = generate_state()\n",
    "    states_seq = [initial_state]\n",
    "    for i in range(nsteps):\n",
    "        old_state = states_seq[-1]\n",
    "        new_state = evolve(old_state)\n",
    "        states_seq.append(new_state)\n",
    "    return states_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "note that we still haven't definide the functions **generate_state** and **evolve**\n",
    "\n",
    "now we implement some stubs\n",
    "\n",
    "what is the easiest way that we can use to make the code run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def generate_state():\n",
    "    return \"stringa\"\n",
    "\n",
    "def evolve(stato):\n",
    "    return stato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stringa', 'stringa', 'stringa', 'stringa', 'stringa', 'stringa']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It might look trivial, but now we have a code that does something, and we can iteratively improve it, instead that trying to generate it perfectly all from nothing\n",
    "\n",
    "This approach lets us divide our problem in sub-problems easier to solve, but requires a bit more abstract reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's start from how we generate our state of the system.\n",
    "\n",
    "which properties do we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As an example, we might requires that:\n",
    "\n",
    "* the state is represented by a string\n",
    "* only two states (characters) are possible, `'.'` ed `'0'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "\n",
    "def generate_state():\n",
    "    return \"stringa\"\n",
    "\n",
    "def evolve(stato):\n",
    "    return stato\n",
    "\n",
    "def simulation(nsteps):\n",
    "    initial_state = generate_state()\n",
    "    states_seq = [initial_state]\n",
    "    for i in range(nsteps):\n",
    "        old_state = states_seq[-1]\n",
    "        new_state = evolve(old_state)\n",
    "        states_seq.append(new_state)\n",
    "    return states_seq\n",
    "\n",
    "########################################################\n",
    "\n",
    "def test_generation_valid_state():\n",
    "    state = generate_state()\n",
    "    assert set(state) == {'.', '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.7, pytest-4.3.0, py-1.8.0, pluggy-0.9.0\n",
      "rootdir: /home/enrico/didattica/corso_programmazione_1819/programmingCourseDIFA, inifile:\n",
      "plugins: xonsh-0.8.11\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_prova.py \u001b[31mF\u001b[0m\u001b[36m                                                          [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ test_generation_valid_state __________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_generation_valid_state():\u001b[0m\n",
      "\u001b[1m        state = generate_state()\u001b[0m\n",
      "\u001b[1m>       assert set(state) == {'.', '0'}\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert {'a', 'g', 'i...'r', 's', ...} == {'.', '0'}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Extra items in the left set:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         'i'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         'g'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         't'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         'n'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         'a'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         's'...\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         ...Full output truncated (6 lines hidden), use '-vv' to show\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:21: AssertionError\n",
      "\u001b[31m\u001b[1m=========================== 1 failed in 0.04 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "\n",
    "def generate_state():\n",
    "    return \"....00......\"\n",
    "\n",
    "def evolve(stato):\n",
    "    return stato\n",
    "\n",
    "def simulation(nsteps):\n",
    "    initial_state = generate_state()\n",
    "    states_seq = [initial_state]\n",
    "    for i in range(nsteps):\n",
    "        old_state = states_seq[-1]\n",
    "        new_state = evolve(old_state)\n",
    "        states_seq.append(new_state)\n",
    "    return states_seq\n",
    "\n",
    "########################################################\n",
    "\n",
    "def test_generation_valid_state():\n",
    "    state = generate_state()\n",
    "    assert set(state) == {'.', '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.7, pytest-4.3.0, py-1.8.0, pluggy-0.9.0\r\n",
      "rootdir: /home/enrico/didattica/corso_programmazione_1819/programmingCourseDIFA, inifile:\r\n",
      "plugins: xonsh-0.8.11\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 1 item                                                               \u001b[0m\r\n",
      "\r\n",
      "test_prova.py \u001b[32m.\u001b[0m\u001b[36m                                                          [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.02 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "our test is passing!\n",
    "\n",
    "sure, our generated state is not very interesting, but at least is a valid one\n",
    "\n",
    "TDD (**Test Driven Development**) help us avoiding over-engineering\n",
    "\n",
    "Do not add functionality to the code before you need them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our next requirement might be that we have only a single `'0'`, to replicate the traditional pictures of the rule 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "\n",
    "def generate_state():\n",
    "    return \"....00......\"\n",
    "\n",
    "def evolve(stato):\n",
    "    return stato\n",
    "\n",
    "def simulation(nsteps):\n",
    "    initial_state = generate_state()\n",
    "    states_seq = [initial_state]\n",
    "    for i in range(nsteps):\n",
    "        old_state = states_seq[-1]\n",
    "        new_state = evolve(old_state)\n",
    "        states_seq.append(new_state)\n",
    "    return states_seq\n",
    "\n",
    "########################################################\n",
    "\n",
    "def test_generation_valid_state():\n",
    "    state = generate_state()\n",
    "    assert set(state) == {'.', '0'}\n",
    "    \n",
    "\n",
    "def test_generation_single_alive():\n",
    "    state = generate_state()\n",
    "    num_of_0 = sum(1 for i in state if i=='0')\n",
    "    assert num_of_0 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.7, pytest-4.3.0, py-1.8.0, pluggy-0.9.0\n",
      "rootdir: /home/enrico/didattica/corso_programmazione_1819/programmingCourseDIFA, inifile:\n",
      "plugins: xonsh-0.8.11\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_prova.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[36m                                                         [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ test_generation_single_alive _________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_generation_single_alive():\u001b[0m\n",
      "\u001b[1m        state = generate_state()\u001b[0m\n",
      "\u001b[1m        num_of_0 = sum(1 for i in state if i=='0')\u001b[0m\n",
      "\u001b[1m>       assert num_of_0 == 1\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 2 == 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:27: AssertionError\n",
      "\u001b[31m\u001b[1m====================== 1 failed, 1 passed in 0.05 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "\n",
    "def generate_state():\n",
    "    return \".....0......\"\n",
    "\n",
    "def evolve(stato):\n",
    "    return stato\n",
    "\n",
    "def simulation(nsteps):\n",
    "    initial_state = generate_state()\n",
    "    states_seq = [initial_state]\n",
    "    for i in range(nsteps):\n",
    "        old_state = states_seq[-1]\n",
    "        new_state = evolve(old_state)\n",
    "        states_seq.append(new_state)\n",
    "    return states_seq\n",
    "\n",
    "########################################################\n",
    "\n",
    "def test_generation_valid_state():\n",
    "    state = generate_state()\n",
    "    assert set(state) == {'.', '0'}\n",
    "    \n",
    "\n",
    "def test_generation_single_alive():\n",
    "    state = generate_state()\n",
    "    num_of_0 = sum(1 for i in state if i=='0')\n",
    "    assert num_of_0 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.7, pytest-4.3.0, py-1.8.0, pluggy-0.9.0\r\n",
      "rootdir: /home/enrico/didattica/corso_programmazione_1819/programmingCourseDIFA, inifile:\r\n",
      "plugins: xonsh-0.8.11\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 2 items                                                              \u001b[0m\r\n",
      "\r\n",
      "test_prova.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                         [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.02 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The final result\n",
    "\n",
    "                            █                    \n",
    "                           ███                   \n",
    "                          ██  █                  \n",
    "                         ██ ████                 \n",
    "                        ██  █   █                \n",
    "                       ██ ████ ███               \n",
    "                      ██  █    █  █              \n",
    "                     ██ ████  ██████             \n",
    "                    ██  █   ███     █            \n",
    "                   ██ ████ ██  █   ███           \n",
    "                  ██  █    █ ████ ██  █          \n",
    "                 ██ ████  ██ █    █ ████         \n",
    "                ██  █   ███  ██  ██ █   █        \n",
    "               ██ ████ ██  ███ ███  ██ ███       \n",
    "              ██  █    █ ███   █  ███  █  █      \n",
    "             ██ ████  ██ █  █ █████  ███████     \n",
    "            ██  █   ███  ████ █    ███      █    \n",
    "           ██ ████ ██  ███    ██  ██  █    ███   \n",
    "          ██  █    █ ███  █  ██ ███ ████  ██  █  \n",
    "         ██ ████  ██ █  ██████  █   █   ███ ████ \n",
    "        ██  █   ███  ████     ████ ███ ██   █   █\n",
    "          ████ ██  ███   █   ██    █   █ █ ███ ██\n",
    "         ██    █ ███  █ ███ ██ █  ███ ██ █ █   █ \n",
    "        ██ █  ██ █  ███ █   █  ████   █  █ ██ ███\n",
    "           ████  ████   ██ █████   █ █████ █  █  \n",
    "          ██   ███   █ ██  █    █ ██ █     █████ \n",
    "         ██ █ ██  █ ██ █ ████  ██ █  ██   ██    █\n",
    "        ██  █ █ ███ █  █ █   ███  ████ █ ██ █  ██\n",
    "          ███ █ █   ████ ██ ██  ███    █ █  ████ \n",
    "         ██   █ ██ ██    █  █ ███  █  ██ ████   █\n",
    "        ██ █ ██ █  █ █  █████ █  ██████  █   █ ██\n",
    "           █ █  ████ ████     ████     ████ ██ █ \n",
    "          ██ ████    █   █   ██   █   ██    █  ██\n",
    "         ██  █   █  ███ ███ ██ █ ███ ██ █  █████ \n",
    "        ██ ████ █████   █   █  █ █   █  ████    █\n",
    "           █    █    █ ███ █████ ██ █████   █  ██\n",
    "          ███  ███  ██ █   █     █  █    █ █████ \n",
    "         ██  ███  ███  ██ ███   ██████  ██ █    █\n",
    "        ██ ███  ███  ███  █  █ ██     ███  ██  ██\n",
    "           █  ███  ███  ██████ █ █   ██  ███ ███ \n",
    "          █████  ███  ███      █ ██ ██ ███   █  █\n",
    "         ██    ███  ███  █    ██ █  █  █  █ █████\n",
    "        ██ █  ██  ███  ████  ██  ██████████ █    \n",
    "           ████ ███  ███   ███ ███          ██   \n",
    "          ██    █  ███  █ ██   █  █        ██ █  \n",
    "         ██ █  █████  ███ █ █ ██████      ██  ██ \n",
    "        ██  ████    ███   █ █ █     █    ██ ███ █\n",
    "          ███   █  ██  █ ██ █ ██   ███  ██  █   █\n",
    "         ██  █ █████ ███ █  █ █ █ ██  ███ ████ ██\n",
    "        ██ ███ █     █   ████ █ █ █ ███   █    █ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## exercise time\n",
    "\n",
    "try to implement the actual simulation by yourself!\n",
    "\n",
    "now you will have to focus implementing the state evolution function:\n",
    "\n",
    "* does it return a valid string?\n",
    "* is it still of the same lenght as the one put as input\n",
    "\n",
    "you will also have to make some choices: how do you manage the borders?\n",
    "\n",
    "* circular border?\n",
    "* reflective border?\n",
    "* constant border?\n",
    "\n",
    "Implementing other rules? 90? 110? 184?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rule30 = {\"000\": '.',\n",
    "          \"00.\": '.',\n",
    "          \"0.0\": '.',\n",
    "          \"...\": '.',\n",
    "          \"0..\": '0',\n",
    "          \".00\": '0',\n",
    "          \".0.\": '0',\n",
    "          \"..0\": '0',\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "RULES = {30: {\"...\": '0', \"..0\": '0', \".0.\": '0', \"000\": '0',\n",
    "              \".00\": '.', \"0..\": '.', \"0.0\": '.', \"00.\": '.'},\n",
    "\n",
    "         90: {\"...\": \"0\", \"..0\": \".\", \".0.\": \"0\", \".00\": \".\",\n",
    "              \"0..\": \".\", \"0.0\": \"0\", \"00.\": \".\", \"000\": \"0\"},\n",
    "\n",
    "         110: {\"...\": '0', \"..0\": '.', \".0.\": '.', \".00\": '0',\n",
    "               \"0..\": '.', \"0.0\": '.', \"00.\": '.', \"000\": '0'},\n",
    "\n",
    "         184: {\"...\": \".\", \"..0\": \"0\", \".0.\": \".\", \".00\": \".\",\n",
    "               \"0..\": \".\", \"0.0\": \"0\", \"00.\": \"0\", \"000\": \"0\"}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Property based testing\n",
    "\n",
    "Pytest automatize our testing procedure, but we still have to think and write a great number of tests, and most of them are going to be similar with small variations\n",
    "\n",
    "The best solution would be for the computer to generate and keep track of tests for us\n",
    "\n",
    "This is not possible in a literal sense, but we can get pretty close to it\n",
    "\n",
    "I can generalize the anecdotal tests I wrote earlier, trying to check not for individual results, but general properties and simmetries of my code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In **unit testing**:\n",
    "    \n",
    "* for each test:\n",
    "    * for each individual case\n",
    "        1. I have to specify the input\n",
    "        2. I have to specify the expected output (or error)\n",
    "        \n",
    "in **property based testing**:\n",
    "\n",
    "* I need to specify the kind of output I will provide to the function\n",
    "* for each test\n",
    "    1. specificy the invariants of that test property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The library I am going to use will specify the input dat in a random way according to the rules I specified.\n",
    "\n",
    "Will trow them at the function actively trying to break it\n",
    "\n",
    "If it finds an example that breaks the expected properties of the functions, tries to find the simplest example that still breaks it\n",
    "\n",
    "keeps track of that example and will provide it to all the future iterations of the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "property based testing does not replace unit testing.\n",
    "\n",
    "It extends it and makes it more powerful, and reduces the amount of trivial and repeated code we have to write\n",
    "\n",
    "Of course, to use it one needs to think harder about what they want to test, but you wouldn't be here if you were afraid of thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The library we are going to use is called [hypothesis](https://hypothesis.readthedocs.io/en/latest/).\n",
    "\n",
    "Hypothesis leverage libraries such as pytest for the basic testing, but generates test automatically using **strategies**.\n",
    "\n",
    "A **strategy** defines how the data are randomly generated and passed to the function to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "from hypothesis import given\n",
    "import hypothesis.strategies as st\n",
    "\n",
    "def inc(x):\n",
    "    if x==5:\n",
    "        return 0\n",
    "    return x + 1\n",
    "\n",
    "def dec(x):\n",
    "    return x - 1\n",
    "\n",
    "@given(value=st.integers())\n",
    "def test_answer_1(value):\n",
    "    print(value)\n",
    "    assert dec(inc(value)) == value\n",
    "    \n",
    "@given(value=st.integers())\n",
    "def test_answer_2(value):\n",
    "    assert dec(inc(value)) == inc(dec(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.0, pytest-3.0.6, py-1.4.32, pluggy-0.4.0\n",
      "rootdir: /home/enrico, inifile: \n",
      "plugins: xonsh-0.5.6, hypothesis-3.6.1\n",
      "collected 2 items \u001b[0m\u001b[1m\n",
      "\u001b[0m\n",
      "test_prova.py .F\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_answer_2 _________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    @given(value=st.integers())\u001b[0m\n",
      "\u001b[1m>   def test_answer_2(value):\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:18: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.6/site-packages/hypothesis/core.py\u001b[0m:524: in wrapped_test\n",
      "\u001b[1m    print_example=True, is_final=True\u001b[0m\n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.6/site-packages/hypothesis/executors.py\u001b[0m:58: in default_new_style_executor\n",
      "\u001b[1m    return function(data)\u001b[0m\n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.6/site-packages/hypothesis/core.py\u001b[0m:111: in run\n",
      "\u001b[1m    return test(*args, **kwargs)\u001b[0m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "value = 5\n",
      "\n",
      "\u001b[1m    @given(value=st.integers())\u001b[0m\n",
      "\u001b[1m    def test_answer_2(value):\u001b[0m\n",
      "\u001b[1m>       assert dec(inc(value)) == inc(dec(value))\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert -1 == 5\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where -1 = dec(0)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where 0 = inc(5)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  and   5 = inc(4)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where 4 = dec(5)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:19: AssertionError\n",
      "---------------------------------- Hypothesis ----------------------------------\n",
      "Falsifying example: test_answer_2(value=5)\n",
      "\u001b[31m\u001b[1m====================== 1 failed, 1 passed in 0.15 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To write property based testing one doesn't need to start from scratch, but can progressively extends the classic unit tests.\n",
    "\n",
    "for a starter, jut replace the fixed parameters with the **just** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_prova.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_prova.py\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def test_answer_1a():\n",
    "    assert inc(3) == 4\n",
    "    \n",
    "\n",
    "from hypothesis import given\n",
    "import hypothesis.strategies as st\n",
    "\n",
    "@given(x=st.just(3))\n",
    "def test_answer_1b(x):\n",
    "    assert inc(x) == x+1\n",
    "    \n",
    "@given(x=st.floats())\n",
    "def test_answer_1c(x):\n",
    "    assert inc(x) == x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.0, pytest-3.0.6, py-1.4.32, pluggy-0.4.0\n",
      "rootdir: /home/enrico, inifile: \n",
      "plugins: xonsh-0.5.6, hypothesis-3.6.1\n",
      "collected 3 items \u001b[0m\u001b[1m\n",
      "\u001b[0m\n",
      "test_prova.py ..F\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_answer_1c ________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    @given(x=st.floats())\u001b[0m\n",
      "\u001b[1m>   def test_answer_1c(x):\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:16: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.6/site-packages/hypothesis/core.py\u001b[0m:524: in wrapped_test\n",
      "\u001b[1m    print_example=True, is_final=True\u001b[0m\n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.6/site-packages/hypothesis/executors.py\u001b[0m:58: in default_new_style_executor\n",
      "\u001b[1m    return function(data)\u001b[0m\n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.6/site-packages/hypothesis/core.py\u001b[0m:111: in run\n",
      "\u001b[1m    return test(*args, **kwargs)\u001b[0m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = nan\n",
      "\n",
      "\u001b[1m    @given(x=st.floats())\u001b[0m\n",
      "\u001b[1m    def test_answer_1c(x):\u001b[0m\n",
      "\u001b[1m>       assert inc(x) == x+1\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert nan == (nan + 1)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where nan = inc(nan)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_prova.py\u001b[0m:17: AssertionError\n",
      "---------------------------------- Hypothesis ----------------------------------\n",
      "Falsifying example: test_answer_1c(x=nan)\n",
      "\u001b[31m\u001b[1m====================== 1 failed, 2 passed in 0.62 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_prova.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we were saying, math on a computer is hard...\n",
    "\n",
    "If we want to ignore some of these cases, we could use the **assume** function, that restricts the random function generation for the testing of each individual function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "from hypothesis import assume\n",
    "\n",
    "@given(x=st.floats())\n",
    "def test_answer_1c(x):\n",
    "    assume(not isnan(x))\n",
    "    assert inc(x) == x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Some) Patterns of properties to be tested\n",
    "\n",
    "The following examples are taken from [this website](http://fsharpforfunandprofit.com/posts/property-based-testing-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Commutative property\n",
    "\n",
    "![](./immagini/property/property_commutative.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Existence of an inverse function\n",
    "\n",
    "![](./immagini/property/property_inverse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conservation law\n",
    "\n",
    "![](./immagini/property/property_invariant.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### idempotence\n",
    "\n",
    "![](./immagini/property/property_idempotence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Induction\n",
    "\n",
    "![](./immagini/property/property_induction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hard to proof, easy to verify\n",
    "\n",
    "![](./immagini/property/property_easy_verification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Oracle testing\n",
    "\n",
    "![](./immagini/property/property_test_oracle.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
